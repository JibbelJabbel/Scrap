name: Web Scraper

on:
  push:
    branches:
      - main
  workflow_dispatch:
  schedule:
    - cron: '0 * * * *'  # Schedule scraping every hour, adjust as necessary

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3  # Using the latest version

    - name: Set up Python
      uses: actions/setup-python@v4  # Using the latest version of setup-python
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas

    - name: Run scraper
      run: |
        python scraper.py  # Your scraping script

    - name: Commit and push CSV
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add statistics_file.csv
        git add singular_phones_file.csv
        git commit -m "Update scraped data" || echo "No changes to commit"
        git push origin HEAD
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Use GITHUB_TOKEN for authentication
